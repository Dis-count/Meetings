刚入学的时候，啥也不会, 走过了很多弯路，今天来总结一下。
<!-- 就给老板建议，可以让师兄们讲讲他们做的工作，也好让我有个入门，没想到到头来还是要自己做这样的工作，算是给师弟师妹们做点贡献吧。 -->
我希望用一种提问互动的形式来进行展示。
最开始接触的是合作博弈，也不知道啥是合作博弈，不知道和线性规划啥关系，没什么兴趣，因为一直比较喜欢算法之类的，上过运筹学觉得里面的问题和解法都比较有意思。我希望把我走过的一些弯路 做过的一些尝试 以及一些挣扎 都讲给你们，希望大家能对自己的工作感兴趣，然后提高学习科研的热情。
其实当时没有动力和兴趣去研究课题主要是没有看到背后的优化问题和算法。因为很难从现有的文章中得到一些基本的优化问题和算法，但这部分又是必需的。所以呢，今天来大致讲一下优化里面都有哪些方法和应用。

最初大家接触的优化 最大最小 基本都是如何求解一个函数的极值，直接求导 或者是对于一般的线性规划都是画出可行域，也就是所谓的图解法，这个我们高中就学过。

内容呢 主要包括五个部分: 刚开始希望通过动态规划进行简单地引入
第二部分是整数和线性规划.
第三部分是一般的优化方法  分为精确算法和近似算法.
第四部分是有关组合优化的内容.  第五部分 是比较杂的部分一般的优化问题.

我想以一个简单的问题作为起始点，也就是背包问题。这样说一般是0-1背包问题。
背包问题就是将物品装进背包，每个物品有自己的重量和价值，背包有一个容量限制,如何选择物品使得在不超过背包容量的前提下装进背包物品的价值达到最大。 我们可以将这个问题建模为一个整数规划模型。
有哪些解法呢？
首先这是一个NPC问题，什么是NPC问题我们后面再说。也就是这个问题是不存在一个多项式算法得到最优解的。如果规模小，我们可以用枚举法,小时候肯定做过类似的题.
规模大的话存在伪多项式时间的动态规划算法。

Partition Equal Subset Sum
<!--
P是否等于NP是计算复杂度理论里面最著名的未解决的问题之一，一个NP完全问题，如果能找到解决它的多项式时间算法，那么就说明了P=NP。

如今0-1背包问题已经被证明是NP完全问题，而它却有着一个动态规划解法，该解法有着O(n*W)的时间复杂度，其中n是物品的个数，W是背包限制的最大负重。所以时间复杂度对输入n，W来说是多项式时间的，所以说明了NP=P！是不是哪里出错了呢？

其实多项式时间是相对于输入规模来说的，输入规模最直观的理解就是输入到该算法的数据占了多少比特内存。0-1背包的输入有n个物品的价值，n个物品的重量，还有背包的最大负重W。如今假设W占用的比特数为L（也就是说背包的最大负重的输入规模是L），那么log(W)=L，所以O(n*W)=O(n*2^L),由此看到，该算法的时间复杂度对于输入规模L来说是指数级别的，随着输入规模L的增加，运算时间会迅速增长。

实际上，人们把这种动态规划的算法称为伪多项式时间算法（pseudo-polynomial time algorithm），这种算法不能真正意义上实现多项式时间内解决问题。 -->
假设 重量w和容量W 是正整数 定义 m[i,w] 装了i件物品总重量不超过w时的最大价值.
那么我们可以得到下面的迭代式
当不装任何物品时,价值为零  事实上这是一个边界条件
当要装的第i个物品重量大于w时,不能装i,显然有 i=i-1
容量可以装下第i个物品时,则需要比较 装和不装 两种方案 取最大

下面这个图表示了计算流程: 先计算第一行,再根据第一行计算第二行 以此类推.


那么动态规划呢，它是一种算法思想，不是具体的算法。
理解动态规划为什么大大会减少计算量非常关键，在某些问题中它的计算复杂度为什么不是指数的，这个是灵活运用的关键。

首先是最优子结构的问题，即他的子问题最优也是可以通过这样的方法求解出来的。比较简单的例子是斐波拉契数列，比如求斐波拉契数列的第n个数，这样的关系式对于求解任何小于n的数都是适用的。同时数列中存在一个关系式，这个是我们能够利用动态规划的关键，这样就会提到状态压缩的概念。状态压缩中找到状态的定义是使用动态规划解决问题的关键。如何提取和定义问题的状态能够帮助我们快速建立起关系式，从而使用动态规划求解。在数列中的状态就为n位数，在背包中状态就为所装物品的数量以及背包的容量。

除了在背包问题中有比较经典的应用，另一个经典的应用是最短路问题，
有向图 源节点 目标节点  对于边(i,j)的成本 w(i,j) 对每条边有一个整数变量表示是否经过这条边.

根据上面的定义, 它的模型就可以写出如下：
尽管最短路问题中有 Dijkstra(正权) (贪心算法，广度优先)
SPFA(负权) Ford 算法，但我们主要看动态规划如何求解，如何定义状态呢？

1）分析最优解的结构

2）递归定义最优解的值

3）自底向上计算最优解的值

4）从计算的最优解的值上面构建出最优解

最短路问题   ob:最短路的一部分也是最短路，反证法即可
            穷举可以，但当是指数的时候就不可以
状态status  -- 节点   f_阶段(状态)
阶段stage   -- 经过的边

最短路问题中可以证明任何最短路的子路径相对于子问题始，终点的路径也是最短的。对应到最优子结构的性质。这样定义了状态为阶段以及步数之后，这个最优阶段序列的任何子序列本身一定是相对于子序列的初始和结束状态的最优阶段序列。这样便可以利用动态规划进行求解。
但是在不同问题中动态规划得到的解不是最优解，原因在于他不满足上面提到的最优结构，因此要注意动态规划求解的条件。
多阶段决策过程，每步求解的问题是后面阶段求解问题的子问题，每步决策将依赖于以前步骤的决策结果。

依次 考虑从 C 到 T 的最短距离。
考虑从 B 到 C 的最短距离
考虑从 A  到 B 的最短距离
考虑从 S 到 A 的最短距离
每次都是最短距离。

在整个过程中，我们把 我们的目标问题转化成了一个个的子问题，在子问题 求 最小值，最后解决了这个问题。

总结因为求解过程是一个多阶段的过程，每一步处理一个子问题，可用于求解组合优化问题。适用条件满足最优子结构的性质。

这里写一个总结??

回头看该问题的整数规划模型，可以看出对应的系数矩阵是 totally unimodular matrix, 该矩阵的特点是
如果 $A \in R^{m\times n}$是整数矩阵，r =rank(A)
而且A的所有非零r×r子式等于 1 或-1，则称A为幺模矩阵, 如果A是幺模矩阵，而且还有其各阶子式均等于0，1或-1，则称A为全幺模矩阵.
显然，全幺模矩阵的所有元素均为0，1或-1。
Totally Unimodular 三个条件
1. 元素均为 +1 -1 0
2. 每一列只有不超过两个的非零元素
3. 行可以分为两组，对于每一列这两组数相加相等。

当然这里面会牵扯到非常多的比较高深的数学知识，但对我们来说重要的是，如果一个整数规划它的矩阵是 totally unimodular, 那么我们就可以利用线性规划来求解它，这是一个非常好的性质。虽然这个性质是可以从 totally unimodular出发得到的，但我们可以从另一个方面来看这里面比较有趣的性质。
回到线性规划的单纯形法解，来到最后一步， 得到解 x* = (B-1b,0)   B-1 = B*/det(B)
矩阵的逆怎么求？克莱姆法则，对于 matrix 的逆必然是正负一，因而解是整数。

那有哪些问题是全单模的呢？
指派问题，最短路，最大流问题

好了这部分的整数规划问题可以转化为线性规划进行求解，那么线性规划大家都很熟悉，尽管单纯形法本身不是多项式可解（在最坏的情况下）但掌握单纯形法的具体流程还是比较重要的，比如我们上述讲整数规划和线性规划关系的时候就用到了，以及一些在单纯形法基础上进行改进的算法，比如二阶段线性规划，掌握检验数，基变量非基变量，基本可行解对于理解基本的列生成算法，割平面方法也是有帮助的。进基出基过程：

单纯形法中看迭代过程  解为 x
可以说，设边的方向为λ，我们沿着边走的距离是θ，那么，我们走的就是 x' = x – θλ
那么λ是什么呢？其实就是选择一个非基的向量（进基过程,检验数），可以理解为梯度方向。
θ就是步长，步长越大越好（出基过程），最大只能走到可行域的顶点。
https://www.hrwhisper.me/introduction-to-simplex-algorithm/
为什么要讲这个呢，因为一直觉得单纯形法很另类，觉得线性规划的解法和一般的优化问题不太一样，但实际还是可以看出是一个梯度下降的过程。
提到了一般的优化问题，那么来看一下针对一般的优化问题都有哪些优化方法。
接着讲分类
分别有精确算法，启发式算法和近似算法。精确算法一般是
分支算法一大类，分支定界最基本的利用定界来减少计算量的方法，分支割可以理解为不断生成割平面添加约束，分支price是分支定界和列生成的结合，主问题子问题分清楚，难点一般在子问题pricing problem(seperation probelm 一般是行生成中的子问题)。
每次计算过程中添加列加快计算过程，这个大家都听了比较多了，了解基本过程之后可以试试简单的例子，做一下总结。这样遇到问题可能需要这个方法的时候就可以很快利用上。

注意分支定界虽然是精确算法 但由于是一个迭代算法，存在收敛的问题，因而通常设置gap 提供终止条件。

约束编程问题 或是约束满足问题
我的理解是 即不需要找到一个最优解，而是要找到满足约束的解  著名的八皇后问题  图着色问题
这种一般是能够建立起满足条件的约束就可以得到问题的解，因而认为一种精确的算法，当然这部分如果是整数规划可以结合割平面，分支定界，动态规划进行求解。

动态规划前面讲了是一种算法思想，掌握它的优化条件，即什么问题适合利用该方法能够得到最优解。

接着是近似方法，近似方法分为启发式算法和近似算法。近似算法是一大类，大家平常见到的 1+\epsilon O(\epsilon^-1) 这类有近似比的算法表述就是近似算法，它的特点是能够表示出算法得到的解与最优解之间的误差，需要的分析知识较多，证明方法多样非常灵活，要求比较高。在调度问题，设施选址问题中出现的比较多。

然后是所谓的现代优化算法，之前我还是比较觉得这类算法比较高大上，但现在不这么想了，当然主要是我自己这么想。主要问题在于算法得到的结果没有办法证明与最优解的关系，也就是没法判断该算法的优劣。只能通过数值实验去证明，适用性和可迁移性不强，需要去试，对一个问题好就是好，但对另一个问题就不好。但我并不是说启发式不重要，在实际生活中，基本不存在能够利用精确算法求解的问题，大多都是利用近似方法求解的，在这里面精确算法和启发式方法都发挥重要的作用。

基本所有的启发式都是为了跳出局部最优解。
分为元启发式和具体问题的启发式，具体问题就是上面说的得到数值结果好就好，也说不出来具体原因。
 “元启发式算法”就是：用来构造启发式算法的一些基础方法。元是一种算法框架，
“启发式算法”就是：利用元启发式算法，结合被求解问题的特征，设计出来的面向特定问题的算法。

基于单个解的元启发式
模拟退火（Simulated Annealing Algorithm）
禁忌搜索（Tabu Search）
变邻域搜索（Variable Neighborhood Search）
自适应大规模领域搜索（Adaptive Large Neighborhood Search）


基于群体（Population-based heuristics）的启发式方法
1、遗传算法（Genetic Algorithm）
2、蚁群算法
3、粒子群算法

启发式算法是相对“最优算法”而言的，其目标是在某种启发原则的引导下搜寻解（这种解一般是局部最优，但可以很大程上接近最优）；贪心算法的核心——贪心准则就是一种启发原则。

说完了不同的算法区别，我们再来看看有哪些经典的缩写问题 像是TSP，VRP，FLP， Production Scheduling Problem
这些问题呢都是组合优化问题，基本上组合优化问题可以分类为 集合划分问题Set Partition 排序问题 选址问题。注意TSP也是一种排序问题。存在大量的离散变量组合的结果，组合数大家都知道是指数增长的，可行解的数量是呈指数增长。要选出一个最优解就变得极为困难。因而找出一种可以高效率解决组合优化问题的算法是大家一直追求的目标。

说到组合优化不得不提到的概念就是NP-难，首先需要了解 P 和 NP的概念，
P类问题：所有可以在多项式时间内求解的判定问题构成P类问题。
判定问题或者说是决策问题：判断是否有一种能够解决某一类问题的算法。
简单来说也就是 是否存在，答案是Yes or No.

NP类问题：所有的非确定性多项式时间可解的判定问题构成NP类问题。
非确定性算法：非确定性算法将问题分解成猜测和验证两个阶段。算法的猜测阶段是非确定性的，算法的验证阶段是确定性的，它验证猜测阶段给出解的正确性。
设算法A是解一个判定问题Q的非确定性算法，如果A的验证阶段能在多项式时间内完成，则称A是一个多项式时间非确定性算法。有些计算问题是确定性的，例如加减乘除，只要按照公式推导，按部就班一步步来，就可以得到结果。但是，有些问题是无法按部就班直接地计算出来。比如，找大质数的问题。有没有一个公式能推出下一个质数是多少呢？这种问题的答案，是无法直接计算得到的，只能通过间接的“猜算”来得到结果。这也就是非确定性问题。而这些问题的通常有个算法，它不能直接告诉你答案是什么，但可以告诉你，某个可能的结果是正确的答案还是错误的。这个可以告诉你“猜算”的答案正确与否的算法，假如可以在多项式（polynomial）时间内算出来，就叫做多项式非确定性问题。

简单来说就是 NP 验证是对的 是多项式容易的。但是算法是不确定的，即求解较难。
比如说 判断给定 一个数N的分解 是否等于两个质数的乘积 K * L 很容易判断是否。但是让你求解 N 是否为质数就是一个非确定算法。


NPC问题：所有的NP问题都可以在多项式时间内转化为 P \in NP，则P是最难的问题。
        称 P \in NPC.
这些问题被称为NP-完全问题(NPC问题)。  也有说NPH的，注意NPC 可以是多项式时间内无法验证正确与否的。

NP-hard 是指优化问题对应的 决策问题是 NPC 完备的。

<!-- 最短路问题 O(m^2)   强多项式时间
解 Ax=b   多项式时间  高斯消元法  n次转轴 n^2 计算  n^3
指派问题  O(n^4)
线性规划  内点法 -->
例子：
刚才说到的质数问题：
如果某人告诉你，数13,717,421可以写成两个较小的数的乘积，你可能不知道是否应该相信他，但是如果他告诉你他可以因式分解为3607乘上3803

又比如我和师弟去美广吃饭，师弟不知道我在哪个位置，但是我告诉师弟我经常坐在电视机下面，a他只需要判断电视机下是不是我就可以了，而不需要绕食堂一周。

<!-- 在一个周六的晚上，你参加了一个盛大的晚会。由于感到局促不安，你想知道这一大厅中是否有你已经认识的人。你的主人向你提议说，你一定认识那位正在甜点盘附近角落的女士罗丝。不费一秒钟，你就能向那里扫视，并且发现你的主人是正确的。然而，如果没有这样的暗示，你就必须环顾整个大厅，一个个地审视每一个人，看是否有你认识的人。
生成问题的一个解通常比验证一个给定的解时间花费要多得多。这是这种一般现象的一个例子。与此类似的是，如果某人告诉你，数13,717,421可以写成两个较小的数的乘积，你可能不知道是否应该相信他，但是如果他告诉你他可以因式分解为3607乘上3803，那么你就可以用一个袖珍计算器容易验证这是对的。人们发现，所有的完全多项式非确定性问题，都可以转换为一类叫做满足性问题的逻辑运算问题。既然这类问题的所有可能答案，都可以在多项式时间内计算，人们于是就猜想，是否这类问题，存在一个确定性算法，可以在多项式时间内，直接算出或是搜寻出正确的答案呢？这就是著名的NP=P？的猜想。 不管我们编写程序是否灵巧，判定一个答案是可以很快利用内部知识来验证，还是没有这样的提示而需要花费大量时间来求解，被看作逻辑和计算机科学中最突出的问题之一。它是斯蒂文·考克于1971年陈述的。 -->

那么像这样的组合问题有哪些解法呢？分支定界，割平面，行生成，列生成，彼此互相组合衍生出来的更为高效的算法，需要具体问题具体分析，但需要掌握最基本的原理。

接下来分析一般的优化问题，最初人们认为，优化问题是线性还是非线性，是不同的优化问题的根本区别。现在呢，优化问题是凸还是非凸才是不同的优化问题之间的根本区别。

那么一类重要的优化问题就是凸优化问题，因为通常我们认为 凸优化因为可以求得最优解，所以在应用上非常重要。

Definition:
凸集概念  凸函数
凸优化问题（OPT，convex optimization problem）指定义在凸集中的凸函数最优化的问题。
要求目标函数是凸函数，变量所属集合是凸集合的优化问题。或者目标函数是凸函数，变量的约束函数是凸函数（不等式约束时），或者是仿射函数（等式约束时）。
（这里写上模型）
\begin{aligned}
\min &\quad f(x) \\
s.t. &\quad g_i(x) \leq 0, i=1,2,...,m \\
    &\quad h_j(x) = 0, j = 1,2,...,n
\end{aligned}

当f(x)和g_i(x)均为凸函数，而h_j(x)均为仿射函数时, 上述的优化问题即凸优化问题。

尽管凸优化的条件比较苛刻，但仍然众多领域有十分广泛的应用，比如说在机器学习中。
因为通常我们认为 凸优化因为可以求得最优解，所以在应用上非常重要。

https://www.jianshu.com/p/6a962fb1b4e0

凸优化的标准问题有四类：
1. Linear Programming(LP)
\[
\begin{aligned}
\min &\quad c^Tx+d \\
s.t. &\quad G(x) \preceq h \\
    &\quad A(x) = b
\end{aligned}
\]
其中目标函数和不等式约束都是仿射函数，且\preceq表示按元素小于等于。

2. Quadratic Programming(QP)

\begin{aligned}
\min &\quad \frac{1}{2}x^TPx+c^Tx+d \\
s.t. &\quad G(x) \preceq h \\
     &\quad A(x) = b
\end{aligned}

其中目标函数为凸二次型，不等式约束为仿射函数。

3. Semidefinite Programming(SDP)

\begin{aligned}
\min &\quad tr(CX) \\
s.t. &\quad tr(A_iX)=b_i, i=1,2,....p \\
     &\quad X \succeq 0
\end{aligned}

其中需要最优化的变量X是一个对称的半正定矩阵，且C, A_1,...,A_p为对阵矩阵。

4. Cone Programming(CP)

那么什么样的问题是凸优化问题或可以通过改变变量而转化为凸优化问题呢：
LP --线性规划
Least squares -- 最小二乘
QP -线性约束的二次规划
SVM --支持向量机
SDP --半正定规划
QCQP -- 二次约束的二次规划
\begin{aligned}
\min &\quad \frac{1}{2}x^TPx+c^Tx+d \\
s.t. &\quad \frac{1}{2}x^TQ_ix + r_ix + s_i \leq 0, i=1,2,....m \\
     &\quad A(x) = b
\end{aligned}

其中目标函数和不等式约束都是凸二次型。

SOCP -- 二阶锥规划
几何规划 多项式乘积形式

凸优化有哪些性质可以让它成为一类重要的优化问题呢？

1. 凸优化问题有一个重要的特性，就是凸优化问题的局部最优解就是全局最优解。
2. 很多非凸问题都可以被等价转化为凸优化问题或者被近似为凸优化问题（例如拉格朗日对偶问题）比如凸松弛方法，（一般是整数规划）首先把问题定义域~X的范围从整型松弛到实值范围内，而且构造一个新的目标函数在定义域上是凸的且小于或者等于原目标函数。或者是将函数近似为一个线性函数。piecewise linear
3. 凸优化问题的研究较为成熟，当一个具体被归为一个凸优化问题，基本可以确定该问题是可被求解的。

凸优化（凸最小化）问题可以用以下几种方法求解：
梯度法(次梯度一般针对不可导的情况)
内点法（有不同的类型）

梯度法的一般求解过程：
由于凸优化问题具有局部最优解即全局最优解的优良特性，因此求解过程可以简化为：找到一个点列使得目标函数值持续减少，直到触发停止条件或达到一个最小值。
设x_k为第k次迭代的值，d_k为第k次搜索方向，\alpha_k为第k次迭代的步长，则第k次迭代公式为：$x_{k+1}=x_k+\alpha_k d_k$
其中第k次的搜索方向满足：
$\triangledown f(x_k)^Td_k < 0$
$f(x_{k+1}) = f(x_k+\alpha_k d_k) < f(x_k)$


最基本的方法是梯度算法，有根据不同问题的性质衍生出来的
随机梯度方法，批量梯度方法

线性搜索法
前面我们提到了单纯形法中旋转操作可以通过一个迭代过程表示出来，这是一个标准的迭代过程。梯度算法重要的两个概念就是 步长和梯度，有一系列分析的条件去讨论这里面的收敛性，这也是前面提到的一些近似算法能够分析出近似比的原因。但我们不用掌握这里面具体的收敛特性所需要满足的条件，其实是因为我不会。而启发式算法中也会有类似的梯度算法，它们只是拿来用也是不分析收敛具体速度的。

全局收敛性关注的是收敛性，也就是说，给定任何的初始点，算法都能收敛到一个驻点。但是局部收敛性更多的关注的是收敛速度。也就是说初始点不能任意选取。
如何选取初始点以及如何跳出局部最优解是启发式算法需要解决的问题。

关于内点法或是罚函数法，或是拉格朗日乘子就不得不提到KKT
以及大名鼎鼎的KKT算法（由KKT这部分可以衍生出二次规划），内点法以及拉格朗日乘子法以及由此产生的对偶算法，对偶算法的强对偶性质。
由此衍生出来的各种梯度算法，批量梯度，随机梯度算法，只要掌握梯度算法的原理即可。以及如果是非凸的函数，可以采用启发式算法，注意启发式算法是一般是没有近似比的，因为作为一种智能算法，有一定的局限性，一般靠经验和调整参数。重点在于能够设计出跳出局部最优解的算法。最后是随机优化有哪些方法。算法思想有哪些，最后要掌握 遇到一个问题用那种方法如何对号入座，这样遇到问题就会有较多的思路，多尝试不同的方法。




具体实践过程中，

他们或者能够保证找到全局解但在求解一些典型的实际问题时代价太大，或者容易陷入局部最优。由于很难加速一个
能保证找到最优解的算法，即对于大多数实际问题很难 找到多项式算法，因为他们大多是NP难问题，那么剩下的
选择就是设计出能够跳离局部最优的算法。

NP-hard 全局最优解极其难找到，因而只能退而求其次，利用启发式算法找到局部最优解。因而启发式算法是有用武之地的，同时在实践过程中线性化方法也是经常用到的，比如之前宣师兄做的需要转化为线性条件加入了 M，从而可以线性化这个条件。

总之我这里只是起了抛砖引玉的作用，还需要大家在平常科研学习中多进行总结，进行知识的更新迭代。问题的性质可以促进你想到相应的算法，从而可以有选择的余地。
最终能够达到遇到一个问题，如何把它抽象建模出来，建模这块我也不太会，需要大家多进行学习总结。也就是定义了这个问题之后，判断这个问题属于哪一类优化问题，如何进行优化方法的选择，有哪些定理保证了可以这么做，为什么要使用这个方法，即这个方法的优点。希望大家能够掌握这些基本的分类之后，可以更好地进行深入的学习。
